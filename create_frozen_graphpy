import tensorflow as tf
import os
from tensorflow import keras
from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2
import numpy as np
import time
from tensorflow.keras.layers import Dense, Flatten, Conv2D
from tensorflow.keras import Model

imageDim = 784
outputDim=10

""" #eager executionがenableになっているか確認
tf.executing_eagerly() """

# MNISTデータセットを使用
mnist = tf.keras.datasets.mnist
(x_train, y_train), (x_test, y_test) = mnist.load_data()

#x_testをpreidctにそのまま投げたら死ぬほど時間かかったからreshapeしている
x_train = x_train.reshape(x_train.shape[0], imageDim)
x_test = x_test.reshape(x_test.shape[0], imageDim)

# 0~1へ正規化する
x_train, x_test = x_train / 255., x_test / 255.
#print(x_train.shape, x_test.shape, t_train.shape, t_test.shape)

#よくわからんけど予測関数を直接実装する際に必要っぽい？
test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)

#モデル名を定義
f_model = "./models_2_tf"


#モデルを格納するディレクトリを作成
if not os.path.isdir(f_model):
  os.makedirs(f_model)

#modelを定義
""" model = tf.keras.models.Sequential([
    tf.keras.layers.Flatten(input_shape=(784,), name='inputs'),
    tf.keras.layers.Dense(10),
    tf.keras.layers.Dense(10, activation='softmax', name='softmax')
], name='Sequential') """

class MyModel(Model):
  def __init__(self):
    super(MyModel, self).__init__()
    self.d1=Dense(units=outputDim,input_shape=(784,))
    self.d2=Dense(10,activation="softmax")
  def call(self, x):
    x = self.d1(x)
    return self.d2(x)
#model.summary()

#モデルのインスタンスを作成
model=MyModel()

# 2.モデルのコンパイル
model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy'])


#モデルを学習させる
model.fit(x_train, y_train, epochs=1, verbose=1,
          validation_data=(x_test, y_test))

#モデルを評価する
model.evaluate(x_test, y_test, verbose=1)

#predictを高速化するためにmodel.predict部分を直接実装する際に必要なパラメータ群
loss_object = tf.keras.losses.SparseCategoricalCrossentropy()
test_loss = tf.keras.metrics.Mean(name='test_loss')
test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(
    name='test_accuracy')

#静的グラフとして計算するためにpredict部分を直接実装


@tf.function
def test_step(test_data):
  model(test_data)


start = time.perf_counter()
n_loop = 5
step=0
for n in range(n_loop):
    for x, y in test_ds:
        test_step(x)
        step+=step+1
        if (step % 1000 == 0):
          print(step)

print('-' * 30)
print('elapsed time for {} prediction {} [msec]'.format(
    len(x_test), (time.perf_counter()-start) * 1000 / n_loop))


#modelをconcretefunction化する
full_model = tf.function(lambda x: model(x))
full_model = full_model.get_concrete_function(
    x=tf.TensorSpec(model.inputs[0].shape, model.inputs[0].dtype))

# Get frozen ConcreteFunction
frozen_func = convert_variables_to_constants_v2(full_model)
frozen_func.graph.as_graph_def()

layers = [op.name for op in frozen_func.graph.get_operations()]
print("-" * 60)
print("Frozen model layers: ")
for layer in layers:
    print(layer)
print("-" * 60)
print("Frozen model inputs: ")
print(frozen_func.inputs)
print("Frozen model outputs: ")
print(frozen_func.outputs)

tf.io.write_graph(graph_or_graph_def=frozen_func.graph,
                  logdir="./ex8_frozen_models",
                  name="frozen_graph.pb",
                  as_text=True)
